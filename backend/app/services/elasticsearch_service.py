"""
Elasticsearch Query Service
Executa queries e processa resultados para visualiza√ß√µes
"""

from typing import Dict, Any, List, Optional
import logging
import hashlib
import json
from app.db.elasticsearch import get_es_client
from app.services.es_client_factory import ESClientFactory
from app.services.cache_service import get_cache_service

logger = logging.getLogger(__name__)


class ElasticsearchService:
    """Service para executar queries Elasticsearch"""

    async def execute_query(
        self,
        index: str,
        query: Dict[str, Any],
        server_id: Optional[str] = None,
        use_cache: bool = True,
        cache_ttl: int = 300
    ) -> Dict[str, Any]:
        """
        Executa query no Elasticsearch e retorna resultados processados

        Args:
            index: Nome do √≠ndice
            query: Query Elasticsearch
            server_id: ID do servidor ES (opcional, usa padr√£o se None)
            use_cache: Se deve usar cache Redis (padr√£o: True)
            cache_ttl: Tempo de vida do cache em segundos (padr√£o: 5 minutos)

        Returns:
            Dicion√°rio com resultados processados
        """
        try:
            # Generate cache key
            cache_key = None
            cache_service = get_cache_service()

            if use_cache and cache_service.enabled:
                cache_params = {
                    "index": index,
                    "query": query,
                    "server_id": server_id or "default"
                }
                query_hash = hashlib.md5(
                    json.dumps(cache_params, sort_keys=True).encode()
                ).hexdigest()[:12]
                cache_key = f"es:query:{index}:{query_hash}"

                # Try to get from cache
                cached_result = await cache_service.get(cache_key)
                if cached_result:
                    logger.info(f"üéØ Cache HIT for query on index {index}")
                    return cached_result

            # Cache miss or cache disabled: execute query
            logger.info(
                f"üîç Executing ES query on index: {index} "
                f"(server: {server_id or 'default'}, cache: {use_cache})"
            )

            # Usar factory para obter cliente correto
            factory = ESClientFactory()
            es = await factory.get_client(server_id)

            logger.info(f"üìù Query: {json.dumps(query, indent=2)}")

            # Executar query
            response = await es.search(
                index=index,
                body=query
            )

            logger.info(f"‚úÖ Query executed successfully. Hits: {response['hits']['total']['value']}")

            # Debug: log aggregations if present
            if "aggregations" in response:
                logger.debug(f"Aggregations found: {list(response['aggregations'].keys())}")

            # Processar resultados
            processed_results = self._process_results(response, query)

            # Cache the result
            if use_cache and cache_key and cache_service.enabled:
                await cache_service.set(cache_key, processed_results, cache_ttl)
                logger.info(f"üíæ Cached query result for {cache_ttl}s (key: {cache_key})")

            return processed_results

        except Exception as e:
            logger.error(f"‚ùå Error executing ES query: {e}")
            raise

    def _process_results(
        self,
        response: Dict[str, Any],
        query: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Processa resultados do ES para formato de visualiza√ß√£o

        Args:
            response: Resposta do Elasticsearch
            query: Query original

        Returns:
            Dados processados para visualiza√ß√£o
        """
        results = {
            "total": response["hits"]["total"]["value"],
            "took": response["took"],
            "data": []
        }

        # Se tem agrega√ß√µes, processar
        if "aggregations" in response or "aggs" in response:
            aggs = response.get("aggregations") or response.get("aggs")
            logger.info(f"üîç Raw aggregations: {aggs}")
            results["data"] = self._process_aggregations(aggs)
            logger.info(f"üìä Processed data: {results['data']}")

        # Se n√£o tem agrega√ß√µes, retornar documentos
        else:
            results["data"] = self._process_hits(response["hits"]["hits"])

        return results

    def _process_aggregations(self, aggs: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Processa agrega√ß√µes do ES

        Args:
            aggs: Agrega√ß√µes do Elasticsearch

        Returns:
            Lista de dados formatados para visualiza√ß√£o
        """
        data = []

        # Procurar pela agrega√ß√£o "result" (padr√£o que usamos)
        if "result" in aggs:
            result_agg = aggs["result"]

            # Terms aggregation (para pie/bar charts)
            if "buckets" in result_agg:
                for bucket in result_agg["buckets"]:
                    data.append({
                        "label": str(bucket.get("key", "")),
                        "value": bucket.get("doc_count", 0)
                    })

            # Cardinality aggregation (para metrics)
            elif "value" in result_agg:
                data.append({
                    "label": "Total",
                    "value": int(result_agg["value"])
                })

            # Date histogram (para line charts)
            elif "buckets" in result_agg:
                for bucket in result_agg["buckets"]:
                    data.append({
                        "label": bucket.get("key_as_string", bucket.get("key", "")),
                        "value": bucket.get("doc_count", 0)
                    })

        # Se n√£o encontrou "result", tentar processar a primeira agrega√ß√£o
        elif len(aggs) > 0:
            first_key = list(aggs.keys())[0]
            first_agg = aggs[first_key]

            if "buckets" in first_agg:
                for bucket in first_agg["buckets"]:
                    data.append({
                        "label": str(bucket.get("key", "")),
                        "value": bucket.get("doc_count", 0)
                    })
            elif "value" in first_agg:
                data.append({
                    "label": "Total",
                    "value": int(first_agg["value"])
                })

        return data

    def _process_hits(self, hits: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Processa documentos retornados

        Args:
            hits: Lista de hits do ES

        Returns:
            Lista de documentos processados
        """
        data = []
        for hit in hits:
            source = hit.get("_source", {})
            # Para tabelas, incluir todos os campos do documento
            row = {"_id": hit.get("_id")}
            row.update(source)
            data.append(row)
        return data

    async def get_index_mapping(
        self, index: str, server_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Obt√©m o mapping de um √≠ndice

        Args:
            index: Nome do √≠ndice
            server_id: ID do servidor ES (opcional)

        Returns:
            Mapping do √≠ndice
        """
        try:
            factory = ESClientFactory()
            es = await factory.get_client(server_id)
            mapping = await es.indices.get_mapping(index=index)
            return mapping

        except Exception as e:
            logger.error(f"‚ùå Error getting mapping for index {index}: {e}")
            raise

    async def get_fields(
        self, index: str, server_id: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Extrai campos de um √≠ndice com tipos e propriedades

        Args:
            index: Nome do √≠ndice
            server_id: ID do servidor ES (opcional)

        Returns:
            Lista de campos com nome, tipo e propriedades
        """
        try:
            mapping = await self.get_index_mapping(index, server_id)

            # Extrair campos do mapping
            fields = []

            # Mapping est√° no formato: {index_name: {mappings: {properties: {...}}}}
            for idx_name, idx_data in mapping.items():
                properties = idx_data.get("mappings", {}).get("properties", {})
                fields.extend(self._extract_fields_from_properties(properties))

            logger.info(f"‚úÖ Extracted {len(fields)} fields from index {index}")
            return fields

        except Exception as e:
            logger.error(f"‚ùå Error getting fields for index {index}: {e}")
            raise

    def _extract_fields_from_properties(
        self, properties: Dict[str, Any], prefix: str = ""
    ) -> List[Dict[str, Any]]:
        """
        Extrai campos recursivamente do mapping properties

        Args:
            properties: Dict de properties do mapping
            prefix: Prefixo para campos aninhados

        Returns:
            Lista de campos extra√≠dos
        """
        fields = []

        for field_name, field_props in properties.items():
            full_name = f"{prefix}{field_name}" if prefix else field_name
            field_type = field_props.get("type", "object")

            # Campo com tipo definido
            if field_type != "object":
                fields.append({
                    "name": full_name,
                    "type": field_type,
                    "aggregatable": field_props.get("aggregatable", True),
                    "searchable": field_props.get("searchable", True),
                })

            # Se tem sub-properties (nested ou object), processar recursivamente
            if "properties" in field_props:
                nested_fields = self._extract_fields_from_properties(
                    field_props["properties"],
                    prefix=f"{full_name}."
                )
                fields.extend(nested_fields)

            # Se tem fields (multi-fields)
            if "fields" in field_props:
                for sub_field_name, sub_field_props in field_props["fields"].items():
                    fields.append({
                        "name": f"{full_name}.{sub_field_name}",
                        "type": sub_field_props.get("type", "unknown"),
                        "aggregatable": sub_field_props.get("aggregatable", True),
                        "searchable": sub_field_props.get("searchable", True),
                    })

        return fields

    async def list_indices(
        self, pattern: str = "*", server_id: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Lista √≠ndices Elasticsearch que correspondem ao padr√£o

        Args:
            pattern: Padr√£o de √≠ndices (ex: 'log-*', default: '*')
            server_id: ID do servidor ES (opcional)

        Returns:
            Lista de dicion√°rios com informa√ß√µes dos √≠ndices
        """
        try:
            factory = ESClientFactory()
            es = await factory.get_client(server_id)

            # Obter informa√ß√µes dos √≠ndices via cat API
            # Formato: index,docs.count,store.size
            indices_response = await es.cat.indices(
                index=pattern,
                format="json",
                h="index,docs.count,store.size",
                s="index:asc"
            )

            # Filtrar √≠ndices do sistema (come√ßam com .)
            indices = [
                {
                    "name": idx["index"],
                    "docs_count": int(idx.get("docs.count", 0) or 0),
                    "size": idx.get("store.size", "0b")
                }
                for idx in indices_response
                if not idx["index"].startswith(".")
            ]

            logger.info(f"‚úÖ Found {len(indices)} indices matching pattern '{pattern}'")
            return indices

        except Exception as e:
            logger.error(f"‚ùå Error listing indices with pattern '{pattern}': {e}")
            raise

    async def get_index_mapping(
        self, index: str, server_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Obt√©m o mapping completo de um √≠ndice

        Args:
            index: Nome do √≠ndice
            server_id: ID do servidor ES (opcional)

        Returns:
            Mapping do √≠ndice
        """
        try:
            factory = ESClientFactory()
            es = await factory.get_client(server_id)

            mapping = await es.indices.get_mapping(index=index)

            logger.info(f"‚úÖ Got mapping for index {index}")
            return mapping

        except Exception as e:
            logger.error(f"‚ùå Error getting mapping for index {index}: {e}")
            raise

    async def cluster_health(
        self, server_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Obt√©m informa√ß√µes de sa√∫de do cluster Elasticsearch

        Args:
            server_id: ID do servidor ES (opcional)

        Returns:
            Informa√ß√µes de sa√∫de do cluster
        """
        try:
            factory = ESClientFactory()
            es = await factory.get_client(server_id)

            health = await es.cluster.health()

            logger.info(f"‚úÖ Cluster health: {health['status']}")
            return health

        except Exception as e:
            logger.error(f"‚ùå Error getting cluster health: {e}")
            raise

    async def test_connection(
        self, index: str, server_id: Optional[str] = None
    ) -> bool:
        """
        Testa se consegue conectar e acessar o √≠ndice

        Args:
            index: Nome do √≠ndice
            server_id: ID do servidor ES (opcional)

        Returns:
            True se conectou com sucesso
        """
        try:
            factory = ESClientFactory()
            es = await factory.get_client(server_id)
            exists = await es.indices.exists(index=index)

            if exists:
                logger.info(f"‚úÖ Index {index} exists and is accessible")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è Index {index} does not exist")
                return False

        except Exception as e:
            logger.error(f"‚ùå Error testing connection to index {index}: {e}")
            return False


# Singleton instance
_es_service: Optional[ElasticsearchService] = None


def get_es_service() -> ElasticsearchService:
    """Retorna inst√¢ncia do service"""
    global _es_service
    if _es_service is None:
        _es_service = ElasticsearchService()
    return _es_service

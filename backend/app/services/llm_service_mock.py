"""
LLM Service
Processa mensagens do usu√°rio com LLM (Claude via Databricks)
"""

from typing import Optional, Dict, Any, List
import logging
import json

logger = logging.getLogger(__name__)


class LLMService:
    """Service para processamento com LLM"""

    def __init__(self):
        # TODO: Inicializar LangChain + Databricks
        # Por enquanto, vamos usar processamento mock
        self.llm_available = False

    async def process_message(
        self,
        message: str,
        index: str,
        context: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:
        """
        Processa mensagem do usu√°rio e retorna widget spec

        Args:
            message: Mensagem do usu√°rio
            index: √çndice Elasticsearch
            context: Hist√≥rico de mensagens (opcional)

        Returns:
            {
                "explanation": str,
                "visualization_type": str,
                "query": dict,
                "needs_clarification": bool,
                "widget": dict
            }
        """
        logger.info(f"Processing message: {message} (index: {index})")

        # Por enquanto, retorna mock baseado em palavras-chave
        message_lower = message.lower()

        # Primeiro, detectar se √© uma mensagem conversacional (n√£o precisa de widget)
        if self._is_conversational(message_lower):
            response = self._generate_conversational_response(message_lower)
            return {
                "explanation": response,
                "visualization_type": None,
                "query": None,
                "needs_clarification": False,
                "widget": None
            }

        # Detectar se √© uma pergunta geral (n√£o sobre visualiza√ß√£o)
        if self._is_general_question(message_lower):
            response = self._answer_general_question(message_lower)
            return {
                "explanation": response,
                "visualization_type": None,
                "query": None,
                "needs_clarification": False,
                "widget": None
            }

        # Detectar se realmente quer uma visualiza√ß√£o
        if not self._wants_visualization(message_lower):
            return {
                "explanation": "Posso ajudar com visualiza√ß√µes de dados! Me diga o que voc√™ gostaria de ver:\n\n‚Ä¢ Gr√°fico de pizza para distribui√ß√µes\n‚Ä¢ Gr√°fico de barras para compara√ß√µes\n‚Ä¢ Gr√°fico de linhas para tend√™ncias\n‚Ä¢ M√©trica para valores √∫nicos\n\nExemplo: 'mostre um gr√°fico de pizza' ou 'quero ver o total'",
                "visualization_type": None,
                "query": None,
                "needs_clarification": True,
                "widget": None
            }

        # Detectar tipo de visualiza√ß√£o
        viz_type = self._detect_visualization_type(message_lower)

        # Gerar query mock
        query = self._generate_mock_query(message_lower, viz_type)

        # Gerar dados mock
        widget_data = self._generate_mock_data(viz_type)

        result = {
            "explanation": f"Criei uma visualiza√ß√£o do tipo {viz_type} para mostrar {message}",
            "visualization_type": viz_type,
            "query": query,
            "needs_clarification": False,
            "widget": {
                "title": self._generate_title(message),
                "type": viz_type,
                "data": {
                    "query": query,
                    "results": {},
                    "config": widget_data
                }
            }
        }

        logger.info(f"‚úÖ Generated {viz_type} visualization")
        return result

    def _is_conversational(self, message: str) -> bool:
        """Detecta se √© uma mensagem conversacional (sauda√ß√£o, agradecimento, etc)"""
        conversational_patterns = [
            # Sauda√ß√µes (palavra completa ou no in√≠cio)
            (r'\boi\b', r'^oi\s'),
            (r'\bol√°\b', r'^ol√°\s', r'\bola\b', r'^ola\s'),
            (r'\bhey\b', r'\bhi\b', r'\bhello\b'),
            # Agradecimentos
            (r'\bobrigad[oa]\b', r'\bvaleu\b', r'\bthanks\b', r'\bthank you\b'),
            # Despedidas
            (r'\btchau\b', r'\bat√© logo\b', r'\bat√© mais\b', r'\bbye\b', r'\bgoodbye\b'),
            # Perguntas gerais
            (r'\btudo bem\b', r'\bcomo vai\b', r'\be ai\b', r'\be a√≠\b'),
            # Confirma√ß√µes simples (apenas palavra sozinha)
            (r'^\s*ok\s*$', r'^\s*beleza\s*$', r'^\s*legal\s*$', r'^\s*show\s*$', r'^\s*boa\s*$')
        ]

        import re

        # Verificar se a mensagem √© muito curta (at√© 3 palavras)
        if len(message.split()) <= 3:
            for patterns in conversational_patterns:
                for pattern in patterns if isinstance(patterns, tuple) else (patterns,):
                    if re.search(pattern, message, re.IGNORECASE):
                        return True

        return False

    def _generate_conversational_response(self, message: str) -> str:
        """Gera resposta conversacional apropriada"""
        # Sauda√ß√µes
        if any(word in message for word in ["oi", "ol√°", "ola", "hey", "hi", "hello"]):
            return "Ol√°! Como posso ajudar voc√™ a visualizar seus dados? Voc√™ pode me pedir para criar gr√°ficos de pizza, barras, linhas ou mostrar m√©tricas. üòä"

        # Agradecimentos
        if any(word in message for word in ["obrigado", "obrigada", "valeu", "thanks"]):
            return "De nada! Estou aqui para ajudar com suas visualiza√ß√µes. Precisa de mais alguma coisa?"

        # Despedidas
        if any(word in message for word in ["tchau", "at√© logo", "at√© mais", "bye"]):
            return "At√© logo! Volte sempre que precisar criar visualiza√ß√µes! üëã"

        # Perguntas sobre estado
        if any(word in message for word in ["tudo bem", "como vai"]):
            return "Tudo √≥timo! Pronto para criar visualiza√ß√µes incr√≠veis para voc√™. O que gostaria de ver?"

        # Confirma√ß√µes
        if any(word in message for word in ["ok", "beleza", "legal", "show", "boa"]):
            return "√ìtimo! Se precisar de mais alguma visualiza√ß√£o, √© s√≥ pedir!"

        # Default
        return "Estou aqui para ajudar! Me diga o que voc√™ gostaria de visualizar."

    def _is_general_question(self, message: str) -> bool:
        """Detecta se √© uma pergunta geral (n√£o sobre visualiza√ß√£o)"""
        import re

        general_patterns = [
            # Perguntas sobre data/hora
            r'\b(que|qual).*\b(dia|data)\b',
            r'\b(que|qual).*\bhora[s]?\b',
            r'\bhora[s]?\s+(s√£o|sao|√©|e)\b',
            r'\bhoje\b', r'\bhj\b', r'\bagora\b',
            # Perguntas sobre o assistente
            r'\b(quem|o que|que).*\b(voc√™|vc|voce)\b',
            r'\bvoc√™ (√©|e)\b', r'\bvc (√©|e)\b',
            # Pedidos de ajuda
            r'\b(ajuda|help|como.*funciona|o que.*fazer)\b',
            r'\b(pode|consegue|sabe).*fazer\b',
            # Perguntas sobre capacidades
            r'\bque.*posso\b', r'\bo que.*posso\b',
        ]

        for pattern in general_patterns:
            if re.search(pattern, message, re.IGNORECASE):
                return True

        return False

    def _answer_general_question(self, message: str) -> str:
        """Responde perguntas gerais"""
        from datetime import datetime
        import re

        # Perguntas sobre capacidades (verificar primeiro, antes de "o que")
        if re.search(r'\b(o que|que).*\b(pode[s]?|consegue[s]?|sabe[s]?).*\bfazer\b', message, re.IGNORECASE):
            return """Posso fazer v√°rias coisas! üöÄ

‚úÖ Criar visualiza√ß√µes interativas (pizza, barras, linhas, m√©tricas)
‚úÖ Gerar queries Elasticsearch automaticamente
‚úÖ Responder perguntas sobre data, hora
‚úÖ Ajudar com d√∫vidas sobre o dashboard

Quer criar alguma visualiza√ß√£o?"""

        # Perguntas sobre data/hora
        if re.search(r'\b(que|qual).*\b(dia|data)\b|\bhoje\b|\bhj\b', message, re.IGNORECASE):
            now = datetime.now()
            data_formatada = now.strftime("%d/%m/%Y")
            dia_semana = ["segunda", "ter√ßa", "quarta", "quinta", "sexta", "s√°bado", "domingo"][now.weekday()]
            return f"Hoje √© {dia_semana}-feira, {data_formatada}. üìÖ\n\nPosso criar alguma visualiza√ß√£o para voc√™?"

        if re.search(r'\b(que|qual).*\bhora[s]?\b|\bhora[s]?\s+(s√£o|sao|√©|e)\b|\bagora\b', message, re.IGNORECASE):
            now = datetime.now()
            hora_formatada = now.strftime("%H:%M")
            return f"Agora s√£o {hora_formatada}. ‚è∞\n\nQuer visualizar algum dado?"

        # Pedidos de ajuda
        if re.search(r'\bajuda\b|\bhelp\b|\bcomo.*funciona\b', message, re.IGNORECASE):
            return """Posso ajudar voc√™ a criar visualiza√ß√µes! Aqui est√£o alguns exemplos:

üìä **Gr√°ficos dispon√≠veis:**
‚Ä¢ Pizza - "mostre a distribui√ß√£o por categoria"
‚Ä¢ Barras - "compare os valores por regi√£o"
‚Ä¢ Linhas - "mostre a tend√™ncia ao longo do tempo"
‚Ä¢ M√©trica - "qual o total de registros"

üí° **Dicas:**
‚Ä¢ Use linguagem natural
‚Ä¢ Seja espec√≠fico sobre o que quer ver
‚Ä¢ Posso tamb√©m responder perguntas gerais!

O que gostaria de visualizar?"""

        # Perguntas sobre o assistente
        if re.search(r'\b(quem|o que).*\b(voc√™|vc)\b|\bvoc√™ (√©|e)\b', message, re.IGNORECASE):
            return "Sou um assistente de visualiza√ß√£o de dados! ü§ñ\n\nPosso criar gr√°ficos e dashboards interativos a partir dos seus dados no Elasticsearch. Basta me dizer o que voc√™ quer ver!"

        # Default para outras perguntas
        return "Interessante pergunta! Minha especialidade √© criar visualiza√ß√µes de dados. üìä\n\nQue tal me dizer o que voc√™ gostaria de visualizar?"

    def _wants_visualization(self, message: str) -> bool:
        """Detecta se o usu√°rio realmente quer criar uma visualiza√ß√£o"""
        visualization_keywords = [
            # Verbos de a√ß√£o
            "mostre", "mostra", "exiba", "exibir", "crie", "criar", "gere", "gerar",
            "fa√ßa", "fazer", "quero", "preciso", "gostaria",
            # Tipos de gr√°fico
            "gr√°fico", "grafico", "chart", "visualiza√ß√£o", "visualizacao",
            "pizza", "pie", "barra", "bar", "linha", "line", "m√©trica", "metric",
            # An√°lises
            "total", "soma", "count", "m√©dia", "media", "distribui√ß√£o", "distribuicao",
            "comparar", "compara√ß√£o", "comparacao", "tend√™ncia", "tendencia",
            "evolu√ß√£o", "evolucao", "ranking", "top"
        ]

        return any(keyword in message for keyword in visualization_keywords)

    def _detect_visualization_type(self, message: str) -> str:
        """Detecta tipo de visualiza√ß√£o baseado na mensagem"""
        if any(word in message for word in ["pizza", "distribui√ß√£o", "porcentagem", "pie"]):
            return "pie"
        elif any(word in message for word in ["barra", "comparar", "ranking", "top", "bar"]):
            return "bar"
        elif any(word in message for word in ["linha", "tend√™ncia", "tempo", "evolu√ß√£o", "line"]):
            return "line"
        elif any(word in message for word in ["total", "soma", "count", "m√©trica", "metric"]):
            return "metric"
        else:
            # Default: pie
            return "pie"

    def _generate_mock_query(self, message: str, viz_type: str) -> Dict[str, Any]:
        """Gera query Elasticsearch mock"""
        if viz_type == "metric":
            return {
                "size": 0,
                "aggs": {
                    "total": {
                        "value_count": {"field": "_id"}
                    }
                }
            }
        else:
            return {
                "size": 0,
                "aggs": {
                    "data": {
                        "terms": {
                            "field": "category.keyword",
                            "size": 10
                        }
                    }
                }
            }

    def _generate_mock_data(self, viz_type: str) -> Dict[str, Any]:
        """Gera dados mock para visualiza√ß√£o"""
        if viz_type == "metric":
            return {
                "data": [
                    {"label": "Total", "value": 1234}
                ]
            }
        elif viz_type == "pie":
            return {
                "data": [
                    {"label": "Categoria A", "value": 35},
                    {"label": "Categoria B", "value": 25},
                    {"label": "Categoria C", "value": 20},
                    {"label": "Categoria D", "value": 15},
                    {"label": "Outros", "value": 5}
                ]
            }
        elif viz_type == "bar":
            return {
                "data": [
                    {"label": "Jan", "value": 120},
                    {"label": "Fev", "value": 150},
                    {"label": "Mar", "value": 180},
                    {"label": "Abr", "value": 160},
                    {"label": "Mai", "value": 200}
                ]
            }
        elif viz_type == "line":
            return {
                "data": [
                    {"label": "Seg", "value": 30},
                    {"label": "Ter", "value": 45},
                    {"label": "Qua", "value": 38},
                    {"label": "Qui", "value": 52},
                    {"label": "Sex", "value": 48},
                    {"label": "S√°b", "value": 35},
                    {"label": "Dom", "value": 25}
                ]
            }
        else:
            return {"data": []}

    def _generate_title(self, message: str) -> str:
        """Gera t√≠tulo baseado na mensagem"""
        # Capitalizar primeira letra de cada palavra
        return message.strip().capitalize()


# Singleton instance
_llm_service: Optional[LLMService] = None


def get_llm_service() -> LLMService:
    """Retorna inst√¢ncia do service"""
    global _llm_service
    if _llm_service is None:
        _llm_service = LLMService()
    return _llm_service
